{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jog822/CRISPR-GEM/blob/main/CRISPR_GEM_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rn2M7GaFwai"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq79LzjJainu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5939a7a2-037b-451c-bdd7-554fa4ff6488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "import warnings\n",
        "import sklearn\n",
        "from scipy import stats\n",
        "from tables import index\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "keras = tf.keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import sparse_categorical_accuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import MeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoYBdeiNdJWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f505d52-4c20-4014-acf7-efdc1d37a806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder created at /content/drive/MyDrive/GEM\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/MyDrive/GEM'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Folder created at {folder_path}\")\n",
        "else:\n",
        "    print(f\"Folder already exists at {folder_path}\")\n",
        "\n",
        "def extract_transcript_gene_mapping(gtf_file):\n",
        "    transcript_to_gene = {}\n",
        "    if gtf_file.endswith('.gz'):\n",
        "        import gzip\n",
        "        open_func = gzip.open\n",
        "    else:\n",
        "        open_func = open\n",
        "\n",
        "    with open_func(gtf_file, 'rt', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('#'):\n",
        "                continue\n",
        "            fields = line.strip().split('\\t')\n",
        "            if fields[2] == 'transcript':\n",
        "                attributes = dict(item.strip().split(' ') for item in fields[8].split(';') if item.strip())\n",
        "                transcript_id = attributes['transcript_id'].strip('\"')\n",
        "                gene_symbol = attributes['gene_name'].strip('\"')\n",
        "                transcript_to_gene[transcript_id] = gene_symbol\n",
        "    return transcript_to_gene\n",
        "\n",
        "def get_counts(df, prefix, transcript_to_gene):\n",
        "    df4=df.copy()\n",
        "    df4.index=df4.index.map(transcript_to_gene)\n",
        "    df5 = df4[~df4.index.str.contains('ENSG', na=False)]\n",
        "    df2=df5.groupby(df5.index, axis=0).max()\n",
        "    df3=df2.T\n",
        "    input_file=\"/content/drive/MyDrive/GEM/\"+prefix+\"_input_list.csv\"\n",
        "    inputs=pd.read_csv(input_file)\n",
        "    i=inputs['inputs'].tolist()\n",
        "    i2 = [value for value in i if value in df3.columns]\n",
        "    input_df=df3[i2]\n",
        "    input_df.fillna(0, inplace=True)\n",
        "    output_file=\"/content/drive/MyDrive/GEM/\"+prefix+\"_output_list.csv\"\n",
        "    outputs=pd.read_csv(output_file)\n",
        "    o=outputs['outputs'].tolist()\n",
        "    o2 = [value for value in o if value in df3.columns]\n",
        "    o3=list(set(o2) - set(i2))\n",
        "    print('Input Shape: '+str(len(i2)))\n",
        "    print('Output Shape: '+str(len(o2)))\n",
        "    print('New Output Shape: '+str(len(o3)))\n",
        "    output_df=df3[o3]\n",
        "    output_df.fillna(0, inplace=True)\n",
        "    return (input_df, output_df)\n",
        "\n",
        "def traiNN(input_df, output_df, prefix):\n",
        "  output=np.log1p(output_df+1)\n",
        "  inputs=np.log1p(input_df+1)\n",
        "\n",
        "  test_size = 0.15\n",
        "  X_train1, X_test1, Y_train1, Y_test1 = train_test_split(inputs,output, test_size=test_size, random_state=23)\n",
        "  X_train = tf.constant(X_train1.values, dtype=tf.float32)\n",
        "  Y_train = tf.constant(Y_train1.values, dtype=tf.float32)\n",
        "  X_test = tf.constant(X_test1.values, dtype=tf.float32)\n",
        "  Y_test = tf.constant(Y_test1.values, dtype=tf.float32)\n",
        "\n",
        "  %matplotlib inline\n",
        "  %config InlineBackend.figure_format = 'retina'\n",
        "  #@keras.saving.register_keras_serializable(name=\"r_squared\")\n",
        "  def r_squared(y_true, y_pred):\n",
        "      SS_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "      SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
        "      return 1 - (SS_res / (SS_tot + tf.keras.backend.epsilon()))\n",
        "  maxy=max(len(input_df.columns),len(output_df.columns))\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10000, activation='relu', input_shape=(len(input_df.columns),)))\n",
        "  model.add(Dense(10000, activation='relu'))\n",
        "  model.add(Dense(10000, activation='relu'))\n",
        "  model.add(Dense(len(output_df.columns)))\n",
        "  callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "  model.compile(Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8), loss='mean_squared_error', metrics=[r_squared])\n",
        "  epochs = 200\n",
        "  batch_size = 50\n",
        "  validation_split = 0.15\n",
        "  history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
        "                      callbacks=[callback],validation_split=validation_split,\n",
        "                      verbose=0)\n",
        "  predictions = model.predict(X_train)\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  r_squared_values = history_dict['r_squared']\n",
        "  val_r_squared_values = history_dict['val_r_squared']\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(loss_values, 'bo', label='training loss')\n",
        "  plt.plot(val_loss_values, 'r', label='validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.ylim(top=1, bottom=0)\n",
        "  plt.legend()\n",
        "  r2 = \"rÂ²\"\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(r_squared_values, 'bo', label='training '+r2)\n",
        "  plt.plot(val_r_squared_values, 'r', label='validation '+r2)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(r2)\n",
        "  plt.ylim(0, 1)\n",
        "  plt.legend()\n",
        "  plt.savefig('/content/drive/MyDrive/GEM/'+ prefix + \"/\"+prefix+'.png')\n",
        "  plt.show()\n",
        "  predictions = model.predict(X_test)\n",
        "  r2 = r_squared(Y_test, predictions)\n",
        "  print(f\"R-squared (R2) Score on Testing Data: {r2.numpy()}\")\n",
        "  mse = MeanSquaredError()(Y_test, predictions)\n",
        "  print(f\"Mean Squared Error (MSE) on Testing Data: {mse.numpy()}\")\n",
        "  model.save('/content/drive/MyDrive/GEM/'+ prefix + \"/\"+prefix+'.keras')\n",
        "  plt.close()\n",
        "  y_test_flattened = Y_test.numpy().flatten()\n",
        "  y_pred2 = model.predict(X_test)\n",
        "  y_pred_flattened = y_pred2.flatten()\n",
        "  plt.scatter(y_test_flattened, y_pred_flattened)\n",
        "  plt.xlabel('Actual')\n",
        "  plt.ylabel('Predicted')\n",
        "  plt.title('Actual vs Predicted Values')\n",
        "  plt.show()\n",
        "  plt.savefig('/content/drive/MyDrive/GEM/'+ prefix +\"/\"+prefix+ '_dotplot.png')\n",
        "  #Calculate a P Value\n",
        "  n = len(y_test_flattened)\n",
        "  k = X_test.shape[1]\n",
        "  ss_tot = np.sum((y_test_flattened - np.mean(y_test_flattened)) ** 2)\n",
        "  ss_res = np.sum((y_test_flattened - y_pred_flattened) ** 2)\n",
        "  ss_reg = ss_tot - ss_res\n",
        "  ms_reg = ss_reg / k\n",
        "  ms_res = ss_res / (n - k - 1)\n",
        "  f_statistic = ms_reg / ms_res\n",
        "  p_value = 1 - stats.f.cdf(f_statistic, k, n - k - 1)\n",
        "  print(f\"P-value: {p_value}\")\n",
        "  return model, input_df, output_df, r2, mse, p_value\n",
        "\n",
        "def evaluate_her(model, input_df, output_df, input_indices, output_indices):\n",
        "  input_df=input_df.fillna(0, inplace=False)\n",
        "  output_df=output_df.fillna(0, inplace=False)\n",
        "  input_df=pd.DataFrame(np.log1p(input_df+1), columns=input_df.columns, index=input_df.index)\n",
        "  output_df=pd.DataFrame(np.log1p(output_df+1), columns=output_df.columns, index=output_df.index)\n",
        "  evaluater_input=input_df[input_df.index.isin(input_indices)]\n",
        "  evaluater_output=output_df[output_df.index.isin(output_indices)]\n",
        "  others=output_df[output_df.index.isin(input_indices)]\n",
        "  bigE2=input_df[input_df.index.isin(output_indices)]\n",
        "  return evaluater_input, evaluater_output, others, bigE2\n",
        "\n",
        "def process_and_evaluate(input_data, Evaluater, other, bigE, model, prefix, prefix1, output_df, CRISPR):\n",
        "    k=30\n",
        "    results=[]\n",
        "    from sklearn import preprocessing\n",
        "    min_max_scaler=preprocessing.MinMaxScaler()\n",
        "    foldi=None\n",
        "    folda=None\n",
        "    foldko=None\n",
        "    if CRISPR=='CRISPRko':\n",
        "      resultko=[]\n",
        "      foldko=0\n",
        "      for col in input_data.columns:\n",
        "            i4 = input_data.copy()\n",
        "            i4[col] = input_data[col] * foldko\n",
        "            perterb = i4.copy()\n",
        "            E=bigE.copy()\n",
        "            for row in perterb.index:\n",
        "                here = pd.DataFrame(perterb.loc[row]).T\n",
        "                trunk = pd.DataFrame(input_data.loc[row]).T\n",
        "                chang = model.predict(trunk, verbose=0).T\n",
        "                other2 = pd.DataFrame(other.loc[row]).T\n",
        "                predictions = model.predict(here, verbose=0)\n",
        "                predictions1 = predictions.T\n",
        "                other3 = other2.T\n",
        "                for row2 in Evaluater.index:\n",
        "                  E1=pd.DataFrame(E.loc[row2]).T\n",
        "                  E2=model.predict(E1, verbose=0) #####\n",
        "                  r2 = r2_score(E2.T, predictions1)\n",
        "                  mse = mean_squared_error(E2.T, predictions1)\n",
        "                  num2=abs(predictions1 - E2.T)/(other3.values+0.0001)\n",
        "                  num2=abs(predictions1 - E2.T)/(chang+0.0001)\n",
        "                  score = sum(num2) / len(output_df.columns)\n",
        "                  resultko.append({'Gene': col, 'n': row, 'output': row2, 'r2': float(r2), 'MSE': float(mse), 'Score': float(score)})\n",
        "      resultko_df=pd.DataFrame(resultko)\n",
        "      view3=resultko_df.copy()\n",
        "      view4=view3.drop(columns=['n', 'output'])\n",
        "      view2=view4.groupby('Gene').mean()\n",
        "      view2_r2=view2.sort_values(by='r2', ascending=False)\n",
        "      view2_MSE=view2.sort_values(by='MSE', ascending=True)\n",
        "      view2_score=view2.sort_values(by='Score', ascending=True)\n",
        "      view2_score.to_csv('/content/drive/MyDrive/GEM/'+prefix+\"/\"+prefix1+'_output.csv')\n",
        "    elif CRISPR=='CRISPRa':\n",
        "      folda=10\n",
        "      k=15\n",
        "      for col in input_data.columns:\n",
        "        i2 = input_data.copy()\n",
        "        i2[col] = input_data[col] * (1 + k / input_data[col])\n",
        "        perterb = i2.copy()\n",
        "        E=bigE.copy()\n",
        "        for row in perterb.index:\n",
        "            here = pd.DataFrame(perterb.loc[row]).T\n",
        "            other2 = pd.DataFrame(other.loc[row]).T\n",
        "            trunk = pd.DataFrame(input_data.loc[row]).T\n",
        "            chang = model.predict(trunk, verbose=0).T\n",
        "            predictions = model.predict(here, verbose=0)\n",
        "            predictions1 = predictions.T\n",
        "            other3 = other2.T\n",
        "            for row2 in Evaluater.index:\n",
        "              eval=pd.DataFrame(Evaluater.loc[row2]).T\n",
        "              E1=pd.DataFrame(E.loc[row2]).T\n",
        "              E2=model.predict(E1, verbose=0) #####\n",
        "              # r2 = r2_score(eval.T, predictions1)\n",
        "              r2 = r2_score(E2.T, predictions1)\n",
        "              # mse = mean_squared_error(eval.T, predictions1)\n",
        "              mse = mean_squared_error(E2.T, predictions1)\n",
        "              # num2=abs(predictions1 - E2.T)/(other3.values+0.0001)\n",
        "              num2=abs(predictions1 - E2.T)/(chang+0.0001)\n",
        "              score = sum(num2) / len(output_df.columns)\n",
        "              results.append({'Gene': col, 'n': row, 'output': row2, 'r2': float(r2), 'MSE': float(mse), 'Score': float(score)})\n",
        "      results_df = pd.DataFrame(results)\n",
        "      view3=results_df.copy()\n",
        "      view4=view3.drop(columns=['n', 'output'])\n",
        "      view2=view4.groupby('Gene').mean()\n",
        "      view2_r2=view2.sort_values(by='r2', ascending=False)\n",
        "      view2_MSE=view2.sort_values(by='MSE', ascending=True)\n",
        "      view2_score=view2.sort_values(by='Score', ascending=True)\n",
        "      view2_score.to_csv('/content/drive/MyDrive/GEM/'+prefix+\"/\"+prefix1+'_output.csv')\n",
        "      view3.to_csv('/content/drive/MyDrive/GEM/'+prefix+\"/\"+prefix1+'_output_NEW.csv')\n",
        "    elif CRISPR=='CRISPRi':\n",
        "      resulti=[]\n",
        "      foldi=0.1\n",
        "      for col in input_data.columns:\n",
        "            i4 = input_data.copy()\n",
        "            i4[col] = input_data[col]/(1+np.log1p(input_data[col]))\n",
        "            # perterb = pd.DataFrame(min_max_scaler.fit_transform(i4), columns=i4.columns, index=i4.index)\n",
        "            perterb=i4.copy()\n",
        "            E=bigE.copy()\n",
        "            for row in perterb.index:\n",
        "                here = pd.DataFrame(perterb.loc[row]).T\n",
        "                other2 = pd.DataFrame(other.loc[row]).T\n",
        "                trunk = pd.DataFrame(input_data.loc[row]).T\n",
        "                chang = model.predict(trunk, verbose=0).T\n",
        "                predictions = model.predict(here, verbose=0)\n",
        "                predictions1 = predictions.T\n",
        "                other3 = other2.T\n",
        "                for row2 in Evaluater.index:\n",
        "                  E1=pd.DataFrame(E.loc[row2]).T\n",
        "                  E2=model.predict(E1, verbose=0) #####\n",
        "                  r2 = r2_score(E2.T, predictions1)\n",
        "                  mse = mean_squared_error(E2.T, predictions1)\n",
        "                  num2=abs(predictions1 - E2.T)/(chang+0.0001)\n",
        "                  score = sum(num2) / len(output_df.columns)\n",
        "                  resulti.append({'Gene': col, 'n': row, 'output': row2, 'r2': float(r2), 'MSE': float(mse), 'Score': float(score)})\n",
        "      resulti_df=pd.DataFrame(resulti)\n",
        "      view3=resulti_df.copy()\n",
        "      view4=view3.drop(columns=['n', 'output'])\n",
        "      view2=view4.groupby('Gene').mean()\n",
        "      view2_r2=view2.sort_values(by='r2', ascending=False)\n",
        "      view2_MSE=view2.sort_values(by='MSE', ascending=True)\n",
        "      view2_score=view2.sort_values(by='Score', ascending=True)\n",
        "      view2_score.to_csv('/content/drive/MyDrive/GEM/'+prefix+\"/\"+prefix1+'_output.csv')\n",
        "    return\n",
        "\n",
        "\n",
        "def analyze_methods(prefix, CRISPR, input_indices, output_indices):\n",
        "    result_df1=pd.read_csv('/content/drive/MyDrive/GEM/TPM.csv', index_col=0)\n",
        "    gtf_file = \"/content/drive/MyDrive/GEM/gencode.v45.chr_patch_hapl_scaff.annotation.gtf/gencode.v45.chr_patch_hapl_scaff.annotation.gtf\"\n",
        "    transcript_to_gene = extract_transcript_gene_mapping(gtf_file)\n",
        "    threshold = result_df1.shape[1] / 3\n",
        "    filtered_df = result_df1[result_df1.sum(axis=1) >= threshold]\n",
        "    model_scores=[]\n",
        "    os.makedirs('/content/drive/MyDrive/GEM/'+ prefix, exist_ok=True)\n",
        "    suffixes = [\"_1_\", \"_2_\", \"_3_\", \"_4_\", \"_5_\", \"_6_\"]\n",
        "    prefix_list = [prefix + suffix for suffix in suffixes]\n",
        "    for prefix1 in prefix_list:\n",
        "      input_df, output_df= get_counts(filtered_df, prefix, transcript_to_gene)\n",
        "      model, input_df, output_df, r2, mse, p_value =traiNN(input_df, output_df, prefix)\n",
        "      model_scores.append({'Prefix': prefix1, 'r2': float(r2), 'mse': float(mse), 'p_val': float(p_value)})\n",
        "      Tester, evaluater_outputs, other, bigE= evaluate_her(model, input_df, output_df, input_indices, output_indices)\n",
        "      final_save=prefix1+'_view2_score'\n",
        "      final_res=prefix1+'_result_df'\n",
        "      with warnings.catch_warnings():\n",
        "          warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "          process_and_evaluate(Tester, evaluater_outputs, other, bigE, model,prefix, prefix1, output_df, CRISPR)\n",
        "      df = pd.DataFrame(model_scores)\n",
        "      df.to_csv('/content/drive/MyDrive/GEM/'+ prefix +\"/\"+prefix1+ '_train_test_scores.csv', index=False)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "405G1yRK7L0F"
      },
      "source": [
        "# Run it..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efk3WRcfb9sN"
      },
      "outputs": [],
      "source": [
        "#Datasets used for publication:\n",
        "## input_indices=['SRR22560355', 'SRR13018743', 'SRR21009234'] # MSC for chondrogenesis\n",
        "## input_indices=['SRR2453345', 'SRR2453349', 'SRR2453348'] # iPSC for Treg differentiation\n",
        "## input_indices=['SRR7107496', 'SRR7107494', 'SRR7107498'] # OA Cartilage\n",
        "\n",
        "## output_indices=['SRR6337333', 'SRR6337334', 'SRR6337335'] # # Juvenile Cartilage for Chondrogenesis\n",
        "## output_indices=['SRR7107486', 'SRR7107484', 'SRR7107481'] # Healthy Cart for OA compare\n",
        "## output_indices=['SRR25253642', 'SRR25253654', 'SRR25253978'] #Tregs for differentiation\n",
        "\n",
        "prefix='' # Same string you typed into GUI save box,\n",
        "# Make sure input_list and output_list for that string are moved to GEM folder in google drive\n",
        "CRISPR_type='' # CRISPRa, CRISPRi, CRISPRko, OR CRISPRki\n",
        "analyze_methods(prefix, CRISPR_type, input_indices, output_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geCpRz2Fi3FL"
      },
      "source": [
        "# View the results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHftyRKGi2nP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import gmean\n",
        "parent_directory = '/content/drive/MyDrive/GEM'\n",
        "dfs = []\n",
        "suffixes = [\"_1_\", \"_2_\", \"_3_\", \"_4_\", \"_5_\", \"_6_\"]\n",
        "prefix_list = [prefix + suffix for suffix in suffixes]\n",
        "for prefix1 in prefix_list:\n",
        "    csv_file = os.path.join(parent_directory, prefix, prefix1 + \"_output.csv\")\n",
        "    if os.path.exists(csv_file):\n",
        "        df = pd.read_csv(csv_file)\n",
        "        # print(df)\n",
        "        df.rename(columns={\"Score\": prefix1}, inplace=True)\n",
        "        df['rank']=range(1, len(df) + 1)\n",
        "        df.sort_values('Gene', ascending=True, inplace=True)\n",
        "        df.set_index('Gene', inplace=True)\n",
        "        df=df.drop(columns=['MSE', 'r2', 'rank'])\n",
        "        dfs.append(df)\n",
        "merged_df =pd.concat(dfs, axis=1)\n",
        "merged_df['average'] = merged_df.apply(lambda row: gmean(row), axis=1)\n",
        "merged_df.sort_values(by='average', ascending=True).head(50)\n",
        "\n",
        "#OR Search for specific genes\n",
        "# rows_containing_tgf = merged_df[merged_df.index.str.contains('COL2', case=False)]\n",
        "# rows_containing_tgf\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CLS0PV3rLqJ8",
        "yeP6shgCFtPy",
        "fVdr3ktneOTT"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}